########## KRONES TENSOR OBJECT DETECTION ##########

# data and model folders
krones_folder_number="complete"
krones_dataset="$tf_dir/krones"
krones_dataset_dir="$krones_dataset/dataset_$krones_folder_number"
krones_models="$krones_dataset/models/ssd_mobilenet_v1_coco"
krones_config="$krones_models/pipeline.config"
krones_frozen="${krones_models}/frozen_graph"
krones_data="$krones_dataset/data"
krones_train_name="train_$krones_folder_number"
krones_eval_name=""eval_$krones_folder_number""
# train
krones_train_annotations="$krones_dataset_dir/train/annotations"
krones_train_dataset="$krones_dataset_dir/train/images"
krones_train_record="$krones_dataset/data/$krones_train_name.record"
krones_train_csv="$krones_dataset/data/$krones_train_name.csv"
krones_train_label="$krones_dataset/data/label_map.pbtxt"
krones_train_dir="$krones_models/train"

# eval
krones_eval_annotations="$krones_dataset/dataset/eval/annotations"
krones_eval_dataset="$krones_dataset_dir/eval/images"
krones_eval_record="$krones_dataset/data/$krones_eval_name.record"
krones_eval_csv="$krones_dataset/data/$krones_train_name.csv"
krones_eval_label="$krones_dataset/data/label_map.pbtxt"
krones_eval_dir="$krones_models/eval"

# google cloud ML 
gcml_yml="$krones_models/gcml.yml"
gcml_krones="krones_pet_bottles_2"
gcml_krones_packages="dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz"
gcml_krones_config="$gcml_krones/data/pipeline_gcml.config"
gcml_krones_train_dir="$gcml_krones/train"
gcml_krones_eval_dir="$gcml_krones/eval"
gcml_data_dir="$krones_dataset/data_gcml"
gcml_train_record="$gcml_data_dir/train.record"

# train on local machine
# USAGE: krones_train
function krones_train() {
  tf_model_dir;
  python object_detection/train.py \
                         --logtostderr \
                         --pipeline_config_path=${krones_config} \
                         --train_dir=${krones_train_dir}
}

# evaluate on local machine
# USAGE: krones_eval
function krones_eval() {
  tf_model_dir;
  python object_detection/eval.py \
                       --logtostderr \
                       --pipeline_config_path=${krones_config} \
                       --checkpoint_dir=${krones_train_dir}
                       --eval_dir=${krones_eval_dir}
}

# tensorboard on local machine
function krones_tensorboard() {
  tf_model_dir;
  tensorboard --logdir=${krones_models}
}

# export frozen weights on local machine
# usage:
# krones_export CKPT_NUMBER
function krones_export() {
  # go to tensorflow/models/reseaerch directory
  tf_model_dir;
  # get new optimized frozen weights
  python object_detection/export_inference_graph.py \
                         --input_type=image_tensor \
                         --pipeline_config_path=${krones_config} \
                         --trained_checkpoint_prefix=${krones_train_dir}/model.ckpt-$1 \
                         --output_directory=${krones_frozen}_$1
}

# perform inference CKPT_NUMBER
function krones_inference (){
  tf_model_dir;
  echo "using frozen_graph_"$1;
  python object_detection/detection_pipeline.py \
                            --CKPT_NUMBER=$1 \
                            --folder=$2/
}

# create new CSV
function krones_generate_csv (){
  tf_model_dir; p2;
  if [ "$1" = "eval" ]; then 
    python ${krones_dataset}/scripts/xml_to_csv.py \
                                --xml_dir=${krones_eval_annotations} \
                                --csv=${krones_eval_csv}
  else
    python ${krones_dataset}/scripts/xml_to_csv.py \
                                --xml_dir=${krones_train_annotations} \
                                --csv=${krones_train_csv}
  fi
}

# create new TFRecord
# usage: 
#   krones_generate_tfrecord FOLDER_NUMBER
function krones_generate_tfrecord (){
  # set the folder which contains dataset
  krones_folder_number=$1;
  echo ${krones_folder_number};
  # generate
  krones_generate_csv $2;
  if [ "$2" = "eval" ]; then
    python ${krones_dataset}/scripts/generate_tfrecord.py \
                                --dir=${krones_eval_dataset} \
                                --csv=${krones_eval_csv} \
                                --output=${krones_eval_record}
  else
  python ${krones_dataset}/scripts/generate_tfrecord.py \
                                --dir=${krones_train_dataset} \
                                --csv=${krones_train_csv} \
                                --output=${krones_train_record}
  fi
}

# create data folder for GCML training
# usage: 
#   krones_generate_gcml MODEL_NUMBER
function krones_gcml_generate() {
  # copy TFRecord file
  cp ${krones_train_record} ${gcml_train_record}
  # copy labels file
  cp ${krones_train_label} ${gcml_data_dir}
  # copy frozen weights
  cp ${krones_frozen}_$1/model.ckpt.* ${gcml_data_dir}
  # copy checkpoint
  cp ${krones_frozen}_$1/checkpoint ${gcml_data_dir}
  # copy graph
  cp ${krones_frozen}_$1/frozen_inference_graph.pb ${gcml_data_dir}
  # success
  echo "Successfully copied GCML data"
}

# get new trained model from google cloud ML
# usage:
#  krones_get_model_gcml MODEL_NUMBER
function krones_gcml_get() {
# remove old model from download folder
 cd; cd Downloads; rm -rf model.ckpt*; cd;
 # donwload new model from gcml to local train folder
 gsutil cp gs://${gcml_krones_train_dir}/model.ckpt-${1}* ${krones_train_dir} 
 # copy checkpoint file
 gsutil cp gs://${gcml_krones_train_dir}/checkpoint ${krones_train_dir}
 # generate frozen graph
 krones_export $1
}

# copy updated trained model on google cloud ML
function krones_gcml_set() {
  # go to models/research/
  tf_model_dir;
  # remove old model from gcml
  gsutil rm -rf gs://${gcml_krones}/data/model.ckpt*
  # remove old checkpoint
  gsutil rm -rf gs://${gcml_krones}/data/checkpoint
  # remove old graph
  gsutil rm -rf gs://${gcml_krones}/data/frozen_inference_graph.pb
  # copy new model and checkpoint to gcml
  gsutil cp ${gcml_data_dir}/* gs://${gcml_krones}/data
}

# train network on google cloud ML
function krones_gcml_train() {
  # update model on gcml before starting new training
  # krones_set_model_gcml;
  # go to models/research/
  tf_model_dir;
  # packaging
  python setup.py sdist
  # slim packaging
  cd slim; python setup.py sdist; cd ..
  # start gcml training
  gcloud ml-engine jobs submit training object_detection_`date +%s` \
            		       --job-dir=gs://${gcml_krones_train_dir} \
                       --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz \
                       --module-name object_detection.train \
                       --region us-central1 \
		                   --config ${gcml_yml} \
                       -- \
                       --train_dir=gs://${gcml_krones_train_dir} \
                       --pipeline_config_path=gs://${gcml_krones_config};
}

# get trained model and create frozen model
function krones_gcml_export() {
  krones_gcml_get ${1} && krones_export ${1};
}

# tensorboard on krones google cloud ML
function tensorboard_gcml() {
  tensorboard --logdir=gs://krones_pet_bottles
}

# open generate_tfrecord.p in macOS TextEdit for quick editing
function krones_edit_tfrecord() {
  tf_model_dir;
  cd krones/scripts;
  open -e generate_tfrecord.py
}
